{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ebe1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {}\n",
    "data = {'1': '1'}\n",
    "metadata | data | {'11': '11'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8970ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datatrove.executor.local import LocalPipelineExecutor\n",
    "from datatrove.pipeline.dedup import MinhashDedupSignature\n",
    "from datatrove.pipeline.dedup.minhash import (\n",
    "    MinhashConfig,\n",
    "    MinhashDedupBuckets,\n",
    "    MinhashDedupCluster,\n",
    "    MinhashDedupFilter,\n",
    ")\n",
    "from datatrove.pipeline.readers import HuggingFaceDatasetReader\n",
    "from datatrove.pipeline.writers.jsonl import JsonlWriter\n",
    "from datatrove.pipeline.writers.huggingface import HuggingFaceDatasetWriter\n",
    "from datatrove.pipeline.tokens import TokensCounter\n",
    "from datatrove.utils.hashing import HashConfig\n",
    "\n",
    "from eeve.data.utils import _reader_adapter_with_column_info, _writer_adapter_with_column_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd2e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_READER = HuggingFaceDatasetReader('alexantonov/chuvash_russian_parallel', text_key='ru', shuffle_files=False, dataset_options={'split':'train'})\n",
    "INPUT_READER = HuggingFaceDatasetReader('alexantonov/chuvash_russian_parallel', text_key='ru', shuffle_files=False, dataset_options={'split':'train'}, adapter=_reader_adapter_with_column_info, doc_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc20f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen = INPUT_READER.run()\n",
    "# doc = next(iter(gen))\n",
    "# doc.metadata['chv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1160f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataclasses\n",
    "\n",
    "# data = {key: val for key, val in dataclasses.asdict(doc).items() if val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69469090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data |= data.pop(\"metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_buckets = 40\n",
    "hashes_per_bucket = 3\n",
    "n_grams = 4\n",
    "precision = 64\n",
    "language = \"rus_Cyrl\"\n",
    "\n",
    "total_tasks = 6\n",
    "workers = 12\n",
    "\n",
    "BASE_MINHASH_PATH = \"/mnt/d/vscode_projects/eeve/eeve/workdir/minhash_tests\"\n",
    "minhash_base_path = f\"{BASE_MINHASH_PATH}/minhash_parallel\"\n",
    "base_logging_dir = f\"{BASE_MINHASH_PATH}/minhash_logs_parallel\"\n",
    "local_working_dir = f'{BASE_MINHASH_PATH}/minhash_local_parallel'\n",
    "\n",
    "upload_path = 'whatisslove11/dedup_chv_parallel_overall_v123455644'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "minhash_config = MinhashConfig(\n",
    "    hash_config=HashConfig(\n",
    "        precision=precision,\n",
    "        hash_fc=\"sha1\"\n",
    "    ),\n",
    "    n_grams=n_grams,\n",
    "    num_buckets=num_buckets,\n",
    "    hashes_per_bucket=hashes_per_bucket,\n",
    ")\n",
    "\n",
    "stage1 = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        INPUT_READER,\n",
    "        MinhashDedupSignature(\n",
    "            output_folder=f\"{minhash_base_path}/signatures\",\n",
    "            config=minhash_config,\n",
    "            language=language\n",
    "        ),\n",
    "    ],\n",
    "    logging_dir=f'{base_logging_dir}/signatures',\n",
    "    tasks=total_tasks,\n",
    "    workers=workers\n",
    ")\n",
    "\n",
    "stage2 = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        MinhashDedupBuckets(\n",
    "            input_folder=f\"{minhash_base_path}/signatures\",\n",
    "            output_folder=f\"{minhash_base_path}/buckets\",\n",
    "            config=minhash_config,\n",
    "        ),\n",
    "    ],\n",
    "    depends=stage1,\n",
    "    logging_dir=f'{base_logging_dir}/buckets',\n",
    "    tasks=minhash_config.num_buckets,\n",
    "    workers=workers\n",
    ")\n",
    "\n",
    "stage3 = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        MinhashDedupCluster(\n",
    "            input_folder=f\"{minhash_base_path}/buckets\",\n",
    "            output_folder=f\"{minhash_base_path}/remove_ids\",\n",
    "            config=minhash_config,\n",
    "        ),\n",
    "    ],\n",
    "    depends=stage2,\n",
    "    logging_dir=f'{base_logging_dir}/clusters',\n",
    "    tasks=1,\n",
    "    workers=workers\n",
    ")\n",
    "\n",
    "stage4 = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        INPUT_READER,\n",
    "        TokensCounter(),  \n",
    "        MinhashDedupFilter(\n",
    "            input_folder=f\"{minhash_base_path}/remove_ids\",\n",
    "            exclusion_writer=JsonlWriter(f\"{minhash_base_path}/removed\"),\n",
    "        ),\n",
    "        HuggingFaceDatasetWriter(\n",
    "            dataset=upload_path,\n",
    "            private=True,\n",
    "            local_working_dir=local_working_dir, # –Ω–µ–æ–±—è–∑ –∞—Ä–≥\n",
    "            output_filename=\"data/${rank}.parquet\",\n",
    "            cleanup=True, # –Ω—É–∂–Ω–æ –ª–∏ —É–¥–∞–ª—è—Ç—å —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç –ø–æ—Ç–æ–º\n",
    "            adapter=_writer_adapter_with_column_restore\n",
    "        ),\n",
    "    ],\n",
    "    depends=stage3,\n",
    "    logging_dir=f'{base_logging_dir}/clusters',\n",
    "    tasks=minhash_config.num_buckets,\n",
    "    workers=workers\n",
    ")\n",
    "\n",
    "stage4.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "jsonObj = pd.read_json(path_or_buf='/mnt/d/vscode_projects/eeve/notebooks/minhash_parallel/removed/00001.jsonl.gz', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3bdea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonObj['text'][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251801b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd0dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2093642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceadff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = load_dataset('whatisslove11/dedup_chv_parallel_overall_v1234567') # upload_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a377a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfd = dd['train']['ru']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc29d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21589bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def find_substring_in_list(list_of_strings, substring):\n",
    "    for string_item in tqdm(list_of_strings):\n",
    "        if substring in string_item:\n",
    "            return True, string_item\n",
    "    return False, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65408a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_substring_in_list(dd['train']['ru'], '13011000112115200036992')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4befaa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf45b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d93de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import glob\n",
    "\n",
    "def read_remove_file(filename):\n",
    "    \"\"\"–ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª .remove –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = f.read()\n",
    "            numbers = []\n",
    "            # –ß–∏—Ç–∞–µ–º –ø–æ 4 –±–∞–π—Ç–∞ (—Ä–∞–∑–º–µ—Ä –æ–¥–Ω–æ–≥–æ —á–∏—Å–ª–∞)\n",
    "            for i in range(0, len(data), 4):\n",
    "                chunk = data[i:i+4]\n",
    "                if len(chunk) < 4:\n",
    "                    print(f\"‚ö†Ô∏è –ù–µ–ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ {filename}: –æ—Å—Ç–∞—Ç–æ–∫ {len(chunk)} –±–∞–π—Ç\")\n",
    "                    break\n",
    "                # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º —á–∏—Å–ª–æ\n",
    "                num = struct.unpack(\"<I\", chunk)[0]  # <I = little-endian unsigned int\n",
    "                numbers.append(num)\n",
    "            return numbers\n",
    "    except Exception as e:\n",
    "        print(f\"üö® –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {filename}: {e}\")\n",
    "        return []\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:\n",
    "if __name__ == \"__main__\":\n",
    "    for filepath in glob.glob(\"/mnt/d/vscode_projects/eeve/notebooks/minhash_parallel/remove_ids/*.remove\"):\n",
    "        numbers = read_remove_file(filepath)\n",
    "        print(f\"üìÅ {filepath} —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Å–ª–∞: {numbers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea5be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8988d006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION = \"!/‚Äî‚Äù:ÔºÖÔºë„Äà&(„ÄÅ‚îÅ\\\\„Äê#%„Äå„ÄçÔºå„ÄëÔºõ+^]~‚Äú„Ää‚Äû';‚Äô{|‚à∂¬¥[=-`*ÔºéÔºà‚ÄìÔºüÔºÅÔºö$ÔΩû¬´„Äâ,><„Äã)?Ôºâ„ÄÇ‚Ä¶@_.\\\"}‚ñ∫¬ª\" + \"\".join(\n",
    "    map(\n",
    "        chr,\n",
    "        (x for a, b in ((0, 9), (11, 13), (13, 32), (127, 160)) for x in range(a, b)),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16df6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1bfca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SONNET\n",
    "from datatrove.executor.local import LocalPipelineExecutor\n",
    "from datatrove.pipeline.dedup import MinhashDedupSignature\n",
    "from datatrove.pipeline.dedup.minhash import (\n",
    "    MinhashConfig,\n",
    "    MinhashDedupBuckets,\n",
    "    MinhashDedupCluster,\n",
    "    MinhashDedupFilter,\n",
    "    MinhashBuildIndex\n",
    ")\n",
    "from datatrove.pipeline.readers import JsonlReader\n",
    "from datatrove.pipeline.writers.jsonl import JsonlWriter\n",
    "from datatrove.utils.hashing import HashConfig\n",
    "from datatrove.utils.typeshelper import Languages\n",
    "from pathlib import Path\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ MinHash\n",
    "minhash_config = MinhashConfig(\n",
    "    hash_config=HashConfig(precision=64),\n",
    "    num_buckets=14,\n",
    "    hashes_per_bucket=8,\n",
    ")\n",
    "\n",
    "# –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º\n",
    "BASE_PATH = Path(\"./minhash_dedup\")\n",
    "LOGS_FOLDER = BASE_PATH / \"logs\"\n",
    "FIRST_DATASET_PATH = \"path/to/first/dataset\"  # –ø—É—Ç—å –∫ –ø–µ—Ä–≤–æ–º—É (—ç—Ç–∞–ª–æ–Ω–Ω–æ–º—É) –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "SECOND_DATASET_PATH = \"path/to/second/dataset\"  # –ø—É—Ç—å –∫–æ –≤—Ç–æ—Ä–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "TOTAL_TASKS = 100  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á, –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
    "BASE_PATH.mkdir(exist_ok=True)\n",
    "LOGS_FOLDER.mkdir(exist_ok=True)\n",
    "\n",
    "# –≠—Ç–∞–ø 1: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞—Ç—É—Ä –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "stage1_first = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        JsonlReader(FIRST_DATASET_PATH),\n",
    "        MinhashDedupSignature(\n",
    "            output_folder=BASE_PATH / \"signatures_first\",\n",
    "            config=minhash_config,\n",
    "            language=Languages.english\n",
    "        ),\n",
    "    ],\n",
    "    tasks=TOTAL_TASKS,\n",
    "    workers=8,  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á\n",
    "    logging_dir=LOGS_FOLDER / \"signatures_first\",\n",
    ")\n",
    "\n",
    "# –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ —Å–∏–≥–Ω–∞—Ç—É—Ä –ø–µ—Ä–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "stage2_index = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        MinhashBuildIndex(\n",
    "            input_folder=BASE_PATH / \"signatures_first\",\n",
    "            output_folder=BASE_PATH / \"index_first\",\n",
    "            index_name=\"first_dataset\",\n",
    "            config=minhash_config,\n",
    "        ),\n",
    "    ],\n",
    "    tasks=minhash_config.num_buckets,  # –ø–æ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–µ –Ω–∞ –∫–∞–∂–¥—ã–π –±–∞–∫–µ—Ç\n",
    "    workers=minhash_config.num_buckets,\n",
    "    logging_dir=LOGS_FOLDER / \"index_first\",\n",
    "    depends=stage1_first,\n",
    ")\n",
    "\n",
    "# –≠—Ç–∞–ø 3: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞—Ç—É—Ä –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "stage3_second = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        JsonlReader(SECOND_DATASET_PATH),\n",
    "        MinhashDedupSignature(\n",
    "            output_folder=BASE_PATH / \"signatures_second\",\n",
    "            config=minhash_config,\n",
    "            language=Languages.english\n",
    "        ),\n",
    "    ],\n",
    "    tasks=TOTAL_TASKS,\n",
    "    workers=8,\n",
    "    logging_dir=LOGS_FOLDER / \"signatures_second\",\n",
    "    depends=stage2_index,\n",
    ")\n",
    "\n",
    "# –≠—Ç–∞–ø 4: –ù–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É –≤—Ç–æ—Ä—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º –∏ –∏–Ω–¥–µ–∫—Å–æ–º –ø–µ—Ä–≤–æ–≥–æ\n",
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º only_dedup_in_index=True —á—Ç–æ–±—ã —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å –∏–Ω–¥–µ–∫—Å–æ–º\n",
    "stage4_buckets = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        MinhashDedupBuckets(\n",
    "            input_folder=BASE_PATH / \"signatures_second\",\n",
    "            output_folder=BASE_PATH / \"buckets_second\",\n",
    "            index_folder=BASE_PATH / \"index_first\",  # –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–¥–µ–∫—Å –ø–µ—Ä–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "            config=minhash_config,\n",
    "            only_dedup_in_index=True,  # —Ç–æ–ª—å–∫–æ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏–Ω–¥–µ–∫—Å–∞\n",
    "        ),\n",
    "    ],\n",
    "    tasks=minhash_config.num_buckets,\n",
    "    workers=minhash_config.num_buckets,\n",
    "    logging_dir=LOGS_FOLDER / \"buckets_second\",\n",
    "    depends=stage3_second,\n",
    ")\n",
    "\n",
    "# –≠—Ç–∞–ø 5: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
    "stage5_cluster = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        MinhashDedupCluster(\n",
    "            input_folder=BASE_PATH / \"buckets_second\",\n",
    "            output_folder=BASE_PATH / \"remove_ids_second\",\n",
    "            config=minhash_config,\n",
    "            ignore_index_matches=False,  # –≤–∞–∂–Ω–æ: –º—ã —Ö–æ—Ç–∏–º —É—á–∏—Ç—ã–≤–∞—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –∏–Ω–¥–µ–∫—Å–æ–º\n",
    "        ),\n",
    "    ],\n",
    "    tasks=1,  # –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–µ\n",
    "    workers=1,\n",
    "    logging_dir=LOGS_FOLDER / \"clusters_second\",\n",
    "    depends=stage4_buckets,\n",
    ")\n",
    "\n",
    "# –≠—Ç–∞–ø 6: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤—Ç–æ—Ä–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (—É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)\n",
    "stage6_filter = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        JsonlReader(SECOND_DATASET_PATH),\n",
    "        MinhashDedupFilter(\n",
    "            input_folder=BASE_PATH / \"remove_ids_second\",\n",
    "            exclusion_writer=JsonlWriter(BASE_PATH / \"removed_from_second\"),  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —É–¥–∞–ª–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã\n",
    "        ),\n",
    "        JsonlWriter(output_folder=BASE_PATH / \"deduplicated_second\"),  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—Ç–æ—Ä–æ–π –¥–∞—Ç–∞—Å–µ—Ç\n",
    "    ],\n",
    "    tasks=TOTAL_TASKS,\n",
    "    workers=8,\n",
    "    logging_dir=LOGS_FOLDER / \"filter_second\",\n",
    "    depends=stage5_cluster,\n",
    ")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
    "if __name__ == \"__main__\":\n",
    "    # –ó–∞–ø—É—Å–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —ç—Ç–∞–ø–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å—Ç–∏—Ç –≤—Å–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ\n",
    "    stage6_filter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5bf42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEEPSEEK\n",
    "from datatrove.executor.local import LocalPipelineExecutor\n",
    "from datatrove.pipeline.dedup.minhash import (\n",
    "    MinhashConfig,\n",
    "    MinhashDedupSignature,\n",
    "    MinhashDedupBuckets,\n",
    "    MinhashDedupCluster,\n",
    "    MinhashDedupFilter,\n",
    ")\n",
    "from datatrove.pipeline.readers import JsonlReader\n",
    "from datatrove.pipeline.writers.jsonl import JsonlWriter\n",
    "from datatrove.utils.hashing import HashConfig\n",
    "\n",
    "\n",
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è MinHash (–º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–æ–¥ —Å–≤–æ–∏ –Ω—É–∂–¥—ã)\n",
    "minhash_config = MinhashConfig(\n",
    "    hash_config=HashConfig(precision=64),\n",
    "    num_buckets=14,\n",
    "    hashes_per_bucket=8,\n",
    ")\n",
    "\n",
    "# –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º\n",
    "DATASET1_PATH = \"path/to/dataset1\"  # –ü–µ—Ä–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç (–±–∞–∑–∞ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏)\n",
    "DATASET2_PATH = \"path/to/dataset2\"  # –í—Ç–æ—Ä–æ–π –¥–∞—Ç–∞—Å–µ—Ç (–∏–∑ –Ω–µ–≥–æ —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏)\n",
    "OUTPUT_BASE = \"path/to/output\"      # –ü–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "\n",
    "# –≠—Ç–∞–ø 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞—Ç—É—Ä –¥–ª—è –æ–±–æ–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n",
    "stage1_dataset1 = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        JsonlReader(DATASET1_PATH),\n",
    "        MinhashDedupSignature(\n",
    "            output_folder=f\"{OUTPUT_BASE}/signatures_dataset1\",\n",
    "            config=minhash_config,\n",
    "        ),\n",
    "    ],\n",
    "    tasks=100,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á (—Ñ–∞–π–ª–æ–≤) –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
    ")\n",
    "\n",
    "stage1_dataset2 = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        JsonlReader(DATASET2_PATH),\n",
    "        MinhashDedupSignature(\n",
    "            output_folder=f\"{OUTPUT_BASE}/signatures_dataset2\",\n",
    "            config=minhash_config,\n",
    "        ),\n",
    "    ],\n",
    "    tasks=100,\n",
    "    depends=stage1_dataset1,  # –ó–∞–ø—É—Å—Ç–∏—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è stage1_dataset1\n",
    ")\n",
    "\n",
    "# –≠—Ç–∞–ø 2: –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏\n",
    "stage2 = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        MinhashDedupBuckets(\n",
    "            input_folder=f\"{OUTPUT_BASE}/signatures_dataset2\",  # –°–∏–≥–Ω–∞—Ç—É—Ä—ã –≤—Ç–æ—Ä–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "            output_folder=f\"{OUTPUT_BASE}/buckets\",\n",
    "            index_folder=f\"{OUTPUT_BASE}/signatures_dataset1\",  # –°–∏–≥–Ω–∞—Ç—É—Ä—ã –ø–µ—Ä–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–∏–Ω–¥–µ–∫—Å)\n",
    "            config=minhash_config,\n",
    "            only_dedup_in_index=True,  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –¥—É–±–ª–∏ –≤–Ω—É—Ç—Ä–∏ dataset2\n",
    "        ),\n",
    "    ],\n",
    "    tasks=minhash_config.num_buckets,  # –û–¥–Ω–∞ –∑–∞–¥–∞—á–∞ –Ω–∞ –≤–µ–¥—Ä–æ\n",
    "    depends=stage1_dataset2,\n",
    ")\n",
    "\n",
    "# –≠—Ç–∞–ø 3: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
    "stage3 = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        MinhashDedupCluster(\n",
    "            input_folder=f\"{OUTPUT_BASE}/buckets\",\n",
    "            output_folder=f\"{OUTPUT_BASE}/remove_ids\",\n",
    "            config=minhash_config,\n",
    "        ),\n",
    "    ],\n",
    "    tasks=1,\n",
    "    depends=stage2,\n",
    ")\n",
    "\n",
    "# –≠—Ç–∞–ø 4: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
    "stage4 = LocalPipelineExecutor(\n",
    "    pipeline=[\n",
    "        JsonlReader(DATASET2_PATH),  # –ß–∏—Ç–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (dataset2)\n",
    "        MinhashDedupFilter(\n",
    "            input_folder=f\"{OUTPUT_BASE}/remove_ids\",\n",
    "            exclusion_writer=JsonlWriter(f\"{OUTPUT_BASE}/removed\"),  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–¥–∞–ª–µ–Ω–Ω—ã–µ –¥—É–±–ª–∏\n",
    "        ),\n",
    "        JsonlWriter(output_folder=f\"{OUTPUT_BASE}/deduplicated_output\"),  # –†–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "    ],\n",
    "    tasks=100,  # –î–æ–ª–∂–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å stage1_dataset2.tasks\n",
    "    depends=stage3,\n",
    ")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –≤—Å–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
    "stage4.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
