{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T12:10:08.950842Z",
     "iopub.status.busy": "2025-08-08T12:10:08.950473Z",
     "iopub.status.idle": "2025-08-08T12:10:08.957005Z",
     "shell.execute_reply": "2025-08-08T12:10:08.955943Z",
     "shell.execute_reply.started": "2025-08-08T12:10:08.950813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, Any, Literal\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T12:12:31.916658Z",
     "iopub.status.busy": "2025-08-08T12:12:31.915995Z",
     "iopub.status.idle": "2025-08-08T12:12:31.925449Z",
     "shell.execute_reply": "2025-08-08T12:12:31.924591Z",
     "shell.execute_reply.started": "2025-08-08T12:12:31.916632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    model_name: str = \"facebook/nllb-200-distilled-600M\"\n",
    "    dataset_path: str = \"alexantonov/chuvash_russian_parallel\"\n",
    "    load_kwargs: Dict[str, Any] | None = None\n",
    "    test_size: Optional[float] = 0.1\n",
    "    source_column: str = \"ru\"\n",
    "    target_column: str = \"chv\"\n",
    "    src_lang: str = \"rus_Cyrl\"\n",
    "    tgt_lang: str = \"chv_Cyrl\"\n",
    "    max_source_length: int = 256\n",
    "    max_target_length: int = 256\n",
    "    output_dir: str = \"./nllb_run\"\n",
    "    num_train_epochs: int = 3\n",
    "    per_device_train_batch_size: int = 4\n",
    "    per_device_eval_batch_size: int = 4\n",
    "    gradient_accumulation_steps: int = 4\n",
    "    learning_rate: float = 2e-5\n",
    "    weight_decay: float = 0.01\n",
    "    warmup_ratio: float = 0.1\n",
    "    logging_steps: int = 1_000\n",
    "    save_steps: int = 9_000\n",
    "    eval_steps: int = 3_000\n",
    "    save_total_limit: int = 2\n",
    "    evaluation_strategy: str = \"steps\"\n",
    "    logging_dir: str = \"./logs\"\n",
    "    predict_with_generate: bool = True\n",
    "    generation_max_length: int = 256\n",
    "    generation_num_beams: int = 1\n",
    "    seed: int = 42\n",
    "    fp16: bool = True\n",
    "    bf16: bool = False\n",
    "    dataloader_num_workers: int = 4\n",
    "    remove_unused_columns: bool = True\n",
    "    push_to_hub: bool = False\n",
    "    report_to: str = \"none\"\n",
    "    load_best_model_at_end: bool = True\n",
    "    metric_for_best_model: str = \"bleu\"\n",
    "    greater_is_better: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T12:23:48.842482Z",
     "iopub.status.busy": "2025-08-08T12:23:48.841884Z",
     "iopub.status.idle": "2025-08-08T12:23:48.857825Z",
     "shell.execute_reply": "2025-08-08T12:23:48.856702Z",
     "shell.execute_reply.started": "2025-08-08T12:23:48.842452Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _load_dataset_from_path(path: str, test_size: float | None = None, load_kwargs = None) -> DatasetDict:  \n",
    "    load_kwargs = load_kwargs or {}\n",
    "    if path.endswith(\"jsonl\"):\n",
    "        dataset = load_dataset(\"json\", data_files=path, **load_kwargs)\n",
    "    else:\n",
    "        dataset = load_dataset(path, **load_kwargs)\n",
    "    \n",
    "    if test_size is not None and 'test' not in dataset.keys() and 'train' in dataset.keys():\n",
    "        dataset = dataset[\"train\"].train_test_split(\n",
    "            test_size, seed=42, load_from_cache_file=True\n",
    "        )\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def _sample_dataset(\n",
    "    dataset: Dataset,\n",
    "    mode: Literal['random', 'sequential'],\n",
    "    num_samples: int | None = None,\n",
    "    ds_ratio: float | None = None\n",
    ") -> Dataset:\n",
    "    total_samples = len(dataset)\n",
    "\n",
    "    if num_samples is None and ds_ratio is None:\n",
    "        raise ValueError(\"Either num_samples or ds_ratio must be specified\")\n",
    "    if num_samples is not None and ds_ratio is not None:\n",
    "        raise ValueError(\"Only one of num_samples or ds_ratio should be specified, not both\")\n",
    "\n",
    "    total_to_select = num_samples if num_samples is not None else int(total_samples * ds_ratio)\n",
    "    idx = range(total_to_select) if mode =='sequential' else random.sample(range(total_samples), total_to_select)\n",
    "\n",
    "    dataset = dataset.select(idx)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def preprocess_function(batch):\n",
    "    src_texts = batch[config.source_column]\n",
    "    tgt_texts = batch[config.target_column]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        src_texts,\n",
    "        max_length=config.max_source_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            tgt_texts,\n",
    "            max_length=config.max_target_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.strip() for label in decoded_labels]\n",
    "\n",
    "    bleu_res = sacrebleu.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=[[l] for l in decoded_labels]\n",
    "    )\n",
    "    chrf_res = chrf.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=[[l] for l in decoded_labels],\n",
    "        word_order=2  # chrF++\n",
    "    )\n",
    "\n",
    "    gen_lens = [np.count_nonzero(p != tokenizer.pad_token_id) for p in preds]\n",
    "\n",
    "    return {\n",
    "        \"bleu\": bleu_res[\"score\"],\n",
    "        \"chrf++\": chrf_res[\"score\"],\n",
    "        \"gen_len\": float(np.mean(gen_lens)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T12:12:36.953791Z",
     "iopub.status.busy": "2025-08-08T12:12:36.953422Z",
     "iopub.status.idle": "2025-08-08T12:12:37.906609Z",
     "shell.execute_reply": "2025-08-08T12:12:37.905858Z",
     "shell.execute_reply.started": "2025-08-08T12:12:36.953762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "set_seed(config.seed)\n",
    "\n",
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T12:10:20.163639Z",
     "iopub.status.busy": "2025-08-08T12:10:20.162940Z",
     "iopub.status.idle": "2025-08-08T12:10:46.652869Z",
     "shell.execute_reply": "2025-08-08T12:10:46.651921Z",
     "shell.execute_reply.started": "2025-08-08T12:10:20.163612Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "raw_datasets = _load_dataset_from_path(\n",
    "    config.dataset_path,\n",
    "    test_size=config.test_size,\n",
    "    load_kwargs=config.load_kwargs\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    config.model_name,\n",
    "    src_lang=config.src_lang,\n",
    "    tgt_lang=config.tgt_lang,\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T12:23:59.649247Z",
     "iopub.status.busy": "2025-08-08T12:23:59.648525Z",
     "iopub.status.idle": "2025-08-08T12:25:02.204123Z",
     "shell.execute_reply": "2025-08-08T12:25:02.203543Z",
     "shell.execute_reply.started": "2025-08-08T12:23:59.649216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "column_names_train = raw_datasets[\"train\"].column_names\n",
    "\n",
    "sample_train = _sample_dataset(raw_datasets[\"train\"], mode='random', num_samples = 120_000)\n",
    "sample_eval = _sample_dataset(raw_datasets[\"test\"], mode='random', num_samples = 3_000)\n",
    "\n",
    "tokenized_train = sample_train.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=column_names_train if config.remove_unused_columns else None,\n",
    "    desc=\"Tokenizing train split\"\n",
    ")\n",
    "\n",
    "tokenized_eval = sample_eval.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=column_names_train if config.remove_unused_columns else None,\n",
    "    desc=\"Tokenizing val split\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T12:14:38.388235Z",
     "iopub.status.busy": "2025-08-08T12:14:38.387653Z",
     "iopub.status.idle": "2025-08-08T12:14:38.392323Z",
     "shell.execute_reply": "2025-08-08T12:14:38.391468Z",
     "shell.execute_reply.started": "2025-08-08T12:14:38.388207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=\"longest\",\n",
    "    label_pad_token_id=-100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T12:15:58.096647Z",
     "iopub.status.busy": "2025-08-08T12:15:58.096251Z",
     "iopub.status.idle": "2025-08-08T12:15:58.126538Z",
     "shell.execute_reply": "2025-08-08T12:15:58.125899Z",
     "shell.execute_reply.started": "2025-08-08T12:15:58.096615Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=config.output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=config.num_train_epochs,\n",
    "    learning_rate=config.learning_rate,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    weight_decay=config.weight_decay,\n",
    "    warmup_ratio=config.warmup_ratio,\n",
    "\n",
    "    eval_strategy=config.evaluation_strategy,\n",
    "    logging_steps=config.logging_steps,\n",
    "    save_steps=config.save_steps,\n",
    "    eval_steps=config.eval_steps,\n",
    "    save_total_limit=config.save_total_limit,\n",
    "\n",
    "    predict_with_generate=config.predict_with_generate,\n",
    "    generation_max_length=config.generation_max_length,\n",
    "    generation_num_beams=config.generation_num_beams,\n",
    "\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    dataloader_num_workers=config.dataloader_num_workers,\n",
    "\n",
    "    seed=config.seed,\n",
    "    report_to=config.report_to,\n",
    "\n",
    "    remove_unused_columns=False,  \n",
    "    load_best_model_at_end=config.load_best_model_at_end,\n",
    "    metric_for_best_model=config.metric_for_best_model,\n",
    "    greater_is_better=config.greater_is_better,\n",
    "    logging_dir=config.logging_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T12:15:59.737778Z",
     "iopub.status.busy": "2025-08-08T12:15:59.737006Z",
     "iopub.status.idle": "2025-08-08T12:15:59.761046Z",
     "shell.execute_reply": "2025-08-08T12:15:59.760439Z",
     "shell.execute_reply.started": "2025-08-08T12:15:59.737752Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T12:16:03.017869Z",
     "iopub.status.busy": "2025-08-08T12:16:03.017036Z",
     "iopub.status.idle": "2025-08-08T12:16:04.450017Z",
     "shell.execute_reply": "2025-08-08T12:16:04.448156Z",
     "shell.execute_reply.started": "2025-08-08T12:16:03.017842Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
